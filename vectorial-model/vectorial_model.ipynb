{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vectorial-model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valterlucena/recuperacao-informacao/blob/master/vectorial-model/vectorial_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mDzxCFq-pGZ",
        "colab_type": "code",
        "outputId": "0646e95d-92a1-40be-f98d-52bfb7a42e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbTlFLFLcv4R",
        "colab_type": "text"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "Nesta atividade iremos exercitar algumas instanciações do modelo vetorial.\n",
        "\n",
        "Primeiramente, vamos importar nossos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekK3acNE-ykj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_URL = 'https://raw.githubusercontent.com/Benardi/ri_lab_01/master/output/results.csv'\n",
        "news = pd.read_csv(DATA_URL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5jsFStdG5w",
        "colab_type": "text"
      },
      "source": [
        "Agora iremos criar nosso índice invertido, para ser utilizado mais adiante. Utilizaremos a função tokenize da biblioteca NLTK associada à uma expressão regular, que considerará como token apenas as sequências de caracteres não-especiais (com exceção do hífen) ou numéricos que não formem stopwords e quem possuam mais que 2 caracteres.\n",
        "Além disso, refinaremos nosso índice para que o mesmo contenha o *inverse document frequency* (IDF) de cada *posting*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv7r2tNn-2SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isValid(token):\n",
        "  return not bool(re.search(r'\\d', token)) and len(token) > 2\n",
        "\n",
        "def total_documents():\n",
        "  return len(news)\n",
        "\n",
        "def get_tokens(document):\n",
        "  toker = RegexpTokenizer('''\\w+[-']*\\w*''')\n",
        "  stop_words = stopwords.words('portuguese')\n",
        "  return [token for token in toker.tokenize(document.lower()) if isValid(token) and token not in stop_words]\n",
        "\n",
        "def build_index(documents):\n",
        "  index = {}\n",
        "  n = 0\n",
        "  for document in documents:\n",
        "    n += 1\n",
        "    tokens = get_tokens(document)\n",
        "    for token in tokens:\n",
        "      occurrence = tokens.count(token)\n",
        "      if token not in index:\n",
        "        index[token] = {}\n",
        "      if n not in index[token]:\n",
        "        index[token][n] = occurrence\n",
        "  return index\n",
        "\n",
        "index = build_index(news.text)\n",
        "\n",
        "for posting in index:\n",
        "  k = len(index[posting])\n",
        "  idf = round(np.log((total_documents() + 1) / k), 2)\n",
        "  index[posting]['idf'] = idf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcCJeUY0dc2r",
        "colab_type": "text"
      },
      "source": [
        "Um vocabulário dos termos presentes nos documentos nos auxiliará em algumas das instanciações que faremos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuegJp2Zcpk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = index.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfsAbLcldu4J",
        "colab_type": "text"
      },
      "source": [
        "# Instanciações\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeUUm63TAdOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  Calcula a medida de similaridade entre a consulta e um documento\n",
        "  pela representação binária do modelo vetorial\n",
        "'''\n",
        "def binary_representation(query, document):\n",
        "  terms = query.split()\n",
        "  doc_tokens = get_tokens(document)\n",
        "  q = {}\n",
        "  d = {}\n",
        "  for term in terms:\n",
        "    q[term] = 0\n",
        "    d[term] = 0\n",
        "    if term in vocabulary:\n",
        "      q[term] = 1\n",
        "    if term in doc_tokens:\n",
        "      d[term] = 1  \n",
        "  measure = 0\n",
        "  for term in terms:\n",
        "    if q[term] != 0 and d[term] != 0:\n",
        "      measure += q[term] * d[term]  \n",
        "  return measure\n",
        "  \n",
        "'''\n",
        "  Calcula a medida de similaridade entre a consulta e um documento\n",
        "  pela representação TF do modelo vetorial\n",
        "'''\n",
        "def tf_representation(query, document):\n",
        "  terms = query.split()\n",
        "  doc_tokens = get_tokens(document)\n",
        "  q = {}\n",
        "  d = {}\n",
        "  for term in terms:\n",
        "    q[term] = 0\n",
        "    d[term] = 0\n",
        "    if term in vocabulary:\n",
        "      q[term] = terms.count(term)\n",
        "    if term in doc_tokens:\n",
        "      d[term] = doc_tokens.count(term)\n",
        "  measure = 0\n",
        "  for term in terms:\n",
        "    if q[term] != 0 and d[term] != 0:\n",
        "      measure += q[term] * d[term]\n",
        "  return measure\n",
        "\n",
        "'''\n",
        "  Calcula a medida de similaridade entre a consulta e um documento\n",
        "  pela representação TF-IDF do modelo vetorial\n",
        "'''\n",
        "def tf_idf_representation(query, document):\n",
        "  terms = query.split()\n",
        "  doc_tokens = get_tokens(document)\n",
        "  q = {}\n",
        "  d = {}\n",
        "  for term in terms:\n",
        "    q[term] = 0\n",
        "    d[term] = 0\n",
        "    if term in vocabulary:\n",
        "      q[term] = terms.count(term)\n",
        "    if term in doc_tokens:\n",
        "      d[term] = doc_tokens.count(term)\n",
        "  measure = 0\n",
        "  for term in terms:\n",
        "    idf = index[term]['idf']\n",
        "    if q[term] != 0 and d[term] != 0:\n",
        "      measure += q[term] * d[term] * idf\n",
        "  return round(measure, 2)\n",
        "\n",
        "'''\n",
        "  Calcula a medida de similaridade entre a consulta e um documento\n",
        "  pela representação bm25 do modelo vetorial\n",
        "'''\n",
        "def bm25_representation(query, document, k):\n",
        "  terms = query.split()\n",
        "  doc_tokens = get_tokens(document)\n",
        "  matched = [term for term in terms if term in doc_tokens]\n",
        "  measure = 0\n",
        "  for match in matched:\n",
        "    cwq = terms.count(match)\n",
        "    cwd = doc_tokens.count(match)\n",
        "    m = total_documents()\n",
        "    dfw = len(index[match].keys()) - 1\n",
        "    measure += cwq * (((k + 1) * cwd) / (cwd  + k)) * np.log((m + 1) / dfw)\n",
        "  return round(measure, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF7XKxZChlpr",
        "colab_type": "text"
      },
      "source": [
        "# Consultas\n",
        "\n",
        "As consultas realizadas serão:\n",
        "\n",
        "* Jair Bolsonaro\n",
        "* Reforma previdência\n",
        "* Forças armadas\n",
        "\n",
        "Para a consulta utilizando o BM25, utilizaremos k = 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsYFFCg8Zpao",
        "colab_type": "code",
        "outputId": "10577e90-9778-4f9d-e437-8f893ce8ca52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "queries = ['jair bolsonaro', 'reforma previdência', 'forças armadas']\n",
        "\n",
        "data = {\n",
        "    'query': [],\n",
        "    'binary': [],\n",
        "    'tf': [],\n",
        "    'tf_idf': [],\n",
        "    'bm25': []\n",
        "}\n",
        "\n",
        "def get_top_5(results):\n",
        "  return sorted(results, key = lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "for query in queries:\n",
        "  n = 1\n",
        "  binary = []\n",
        "  tf = []\n",
        "  tf_idf = []\n",
        "  bm25 = []\n",
        "  for document in news.text:\n",
        "    binary.append((n, binary_representation(query, document)))\n",
        "    tf.append((n, tf_representation(query, document)))\n",
        "    tf_idf.append((n, tf_idf_representation(query, document)))\n",
        "    bm25.append((n, bm25_representation(query, document, 10)))\n",
        "    n += 1\n",
        "  data['query'].append(query)\n",
        "  data['binary'].append(get_top_5(binary))\n",
        "  data['tf'].append(get_top_5(tf))\n",
        "  data['tf_idf'].append(get_top_5(tf_idf))\n",
        "  data['bm25'].append(get_top_5(bm25))\n",
        "\n",
        "pd.options.display.max_colwidth = 160\n",
        "pd.DataFrame(data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>binary</th>\n",
              "      <th>tf</th>\n",
              "      <th>tf_idf</th>\n",
              "      <th>bm25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jair bolsonaro</td>\n",
              "      <td>[(1, 2), (2, 2), (25, 2), (86, 2), (126, 2)]</td>\n",
              "      <td>[(151, 52), (207, 48), (166, 39), (19, 26), (42, 12)]</td>\n",
              "      <td>[(207, 79.74), (151, 76.2), (166, 54.0), (19, 34.32), (216, 17.1)]</td>\n",
              "      <td>[(207, 27.29), (151, 22.53), (166, 16.13), (19, 10.46), (216, 10.16)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reforma previdência</td>\n",
              "      <td>[(37, 2), (95, 2), (138, 2), (140, 2), (166, 2)]</td>\n",
              "      <td>[(37, 19), (138, 14), (166, 10), (248, 9), (205, 8)]</td>\n",
              "      <td>[(37, 43.14), (138, 31.0), (166, 22.3), (248, 19.96), (205, 17.4)]</td>\n",
              "      <td>[(37, 23.32), (138, 20.03), (166, 16.37), (248, 15.14), (205, 13.04)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>forças armadas</td>\n",
              "      <td>[(1, 2), (6, 2), (12, 2), (25, 2), (42, 2)]</td>\n",
              "      <td>[(150, 15), (25, 9), (166, 8), (208, 8), (1, 6)]</td>\n",
              "      <td>[(150, 33.34), (25, 19.87), (166, 17.96), (208, 17.96), (1, 13.47)]</td>\n",
              "      <td>[(150, 21.01), (25, 15.1), (166, 14.1), (208, 14.1), (1, 11.39)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 query  ...                                                                   bm25\n",
              "0       jair bolsonaro  ...  [(207, 27.29), (151, 22.53), (166, 16.13), (19, 10.46), (216, 10.16)]\n",
              "1  reforma previdência  ...  [(37, 23.32), (138, 20.03), (166, 16.37), (248, 15.14), (205, 13.04)]\n",
              "2       forças armadas  ...       [(150, 21.01), (25, 15.1), (166, 14.1), (208, 14.1), (1, 11.39)]\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}